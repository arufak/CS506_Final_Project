{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e925919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3faa7745",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# TMDb API key\n",
    "api_key = f'013b31dd3339a724725d88524cfb37ba'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a062a854",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_movies_by_keyword_to_dataset(keyword, current_df=None, weather_type=\"\"):\n",
    "    # Define the list of all weather columns\n",
    "    weather_columns = [\"Clear Sky\", \"Few Clouds\", \"Scattered Clouds\", \"Broken Clouds\",\n",
    "                       \"Shower Rain\", \"Rain\", \"Thunderstorm\", \"Snow\", \"Mist\"]\n",
    "    \n",
    "    # Initialize the dataset if it's None\n",
    "    if current_df is None:\n",
    "        current_df = pd.DataFrame(columns=[\n",
    "            \"title\", \"overview\", \"release_date\", \"runtime\", \n",
    "            \"genres\", \"status\", \"original_language\", \"tagline\", \"popularity\", \n",
    "            \"vote_average\", \"vote_count\", \"cast\", \"director\", \"producer\", \n",
    "            \"cinematographer\", \"poster\", \"keywords\", \"production_companies\", \n",
    "            \"production_countries\", \"budget\", \"revenue\"\n",
    "        ] + weather_columns)\n",
    "    \n",
    "    # Step 1: Search for the keyword to get the keyword ID\n",
    "    keyword_url = f'https://api.themoviedb.org/3/search/keyword?api_key={api_key}&query={keyword}'\n",
    "    keyword_response = requests.get(keyword_url).json()\n",
    "    \n",
    "    # Check if the keyword exists\n",
    "    if not keyword_response['results']:\n",
    "        print(f\"No results found for keyword '{keyword}'.\")\n",
    "        return current_df\n",
    "    \n",
    "    keyword_id = keyword_response['results'][0]['id']\n",
    "    print(f\"Found keyword '{keyword}' with ID: {keyword_id}\")\n",
    "    \n",
    "    # Step 2: Use the keyword ID to get associated movies (with pagination)\n",
    "    page = 1\n",
    "    movie_data = []\n",
    "    \n",
    "    while True:\n",
    "        movie_url = f'https://api.themoviedb.org/3/keyword/{keyword_id}/movies?api_key={api_key}&page={page}'\n",
    "        movie_response = requests.get(movie_url).json()\n",
    "        \n",
    "        # Break if no more results\n",
    "        if 'results' not in movie_response or not movie_response['results']:\n",
    "            break\n",
    "        \n",
    "        # Process each movie in the current page\n",
    "        for movie in movie_response['results']:\n",
    "            movie_id = movie['id']\n",
    "            details_url = f'https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}&append_to_response=credits,keywords'\n",
    "            details_response = requests.get(details_url).json()\n",
    "            \n",
    "            # Extract required fields\n",
    "            movie_info = {\n",
    "                \"title\": details_response.get(\"title\"),\n",
    "                \"overview\": details_response.get(\"overview\", \"No overview available\"),\n",
    "                \"release_date\": details_response.get(\"release_date\", \"No release date\"),\n",
    "                \"runtime\": details_response.get(\"runtime\"),\n",
    "                \"genres\": [genre[\"name\"] for genre in details_response.get(\"genres\", [])],\n",
    "                \"status\": details_response.get(\"status\"),\n",
    "                \"original_language\": details_response.get(\"original_language\"),\n",
    "                \"tagline\": details_response.get(\"tagline\"),\n",
    "                \"popularity\": details_response.get(\"popularity\"),\n",
    "                \"vote_average\": details_response.get(\"vote_average\"),\n",
    "                \"vote_count\": details_response.get(\"vote_count\"),\n",
    "                \"production_companies\": [company[\"name\"] for company in details_response.get(\"production_companies\", [])],\n",
    "                \"production_countries\": [country[\"name\"] for country in details_response.get(\"production_countries\", [])],\n",
    "                \"budget\": details_response.get(\"budget\"),\n",
    "                \"revenue\": details_response.get(\"revenue\"),\n",
    "                \"poster\": f\"https://image.tmdb.org/t/p/w500{details_response.get('poster_path')}\" if details_response.get(\"poster_path\") else None,\n",
    "                \"keywords\": [keyword[\"name\"] for keyword in details_response.get(\"keywords\", {}).get(\"keywords\", [])]\n",
    "            }\n",
    "            \n",
    "            # Process cast: Get top 3 actors with real name and character name\n",
    "            cast = details_response.get(\"credits\", {}).get(\"cast\", [])\n",
    "            top_cast = [{\"name\": member[\"name\"], \"character\": member[\"character\"]} for member in cast[:3]]\n",
    "            movie_info[\"cast\"] = top_cast\n",
    "            \n",
    "            # Process crew: Only director, producer, and cinematographer\n",
    "            crew = details_response.get(\"credits\", {}).get(\"crew\", [])\n",
    "            for member in crew:\n",
    "                if member[\"job\"] == \"Director\":\n",
    "                    movie_info[\"director\"] = member[\"name\"]\n",
    "                elif member[\"job\"] == \"Producer\":\n",
    "                    movie_info[\"producer\"] = member[\"name\"]\n",
    "                elif member[\"job\"] == \"Director of Photography\":\n",
    "                    movie_info[\"cinematographer\"] = member[\"name\"]\n",
    "\n",
    "            # Set weather type columns: 1 for the specified weather, 0 for others\n",
    "            for weather in weather_columns:\n",
    "                movie_info[weather] = 1 if weather == weather_type else 0\n",
    "\n",
    "            # Append the movie info to movie_data list\n",
    "            movie_data.append(movie_info)\n",
    "        \n",
    "        # Print progress and move to the next page\n",
    "        print(f\"Processed page {page} for keyword '{keyword}' under weather type '{weather_type}'.\")\n",
    "        page += 1\n",
    "\n",
    "    # Convert movie_data list to a DataFrame and append to current_df\n",
    "    new_movies_df = pd.DataFrame(movie_data)\n",
    "    updated_df = pd.concat([current_df, new_movies_df], ignore_index=True)\n",
    "    print(f\"Added {len(new_movies_df)} movies with keyword '{keyword}' under weather type '{weather_type}'.\")\n",
    "    \n",
    "    return updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_keywords2 = {\n",
    "    \"Clear Sky\": [\n",
    "        \"Clear Sky\", \"Uplifting\", \"Light-hearted\", \"Inspirational\", \"Joyful\", \"Adventurous\",\n",
    "        \"Happy\", \"Cheerful\", \"Sunny\", \"Free-spirited\", \"Positive\", \"Bright\",\n",
    "        \"Fun\", \"Playful\", \"Energetic\", \"Optimistic\", \"Joyous\", \"Carefree\", \n",
    "        \"Exhilarating\", \"Wholesome\", \"Feel-good\", \"Empowering\", \"High-energy\", \n",
    "        \"Dream-chasing\", \"Fun-filled\"\n",
    "    ],\n",
    "    \"Few Clouds\": [\n",
    "        \"Few Clouds\", \"Playful\", \"Relaxed\", \"Nostalgic\", \"Romantic\", \"Warm\", \"Cozy\",\n",
    "        \"Soothing\", \"Leisurely\", \"Charming\", \"Heartwarming\", \"Sweet\", \"Dreamy\",\n",
    "        \"Sentimental\", \"Delightful\", \"Calming\", \"Endearing\", \"Soft-hearted\", \n",
    "        \"Tender\", \"Whimsical\", \"Lighthearted\", \"Comforting stories\", \"Dreamlike\", \n",
    "        \"Affectionate\", \"Amusing\", \"Chilled-out\"\n",
    "    ],\n",
    "    \"Scattered Clouds\": [\n",
    "        \"Scattered Clouds\", \"Reflective\", \"Curious\", \"Intense\", \"Melancholic\", \"Thoughtful\",\n",
    "        \"Brooding\", \"Intriguing\", \"Pensive\", \"Questioning\", \"Somber\", \"Mellow\",\n",
    "        \"Deep\", \"Insightful\", \"Soulful\", \"Wistful\", \"Philosophical\", \"Poignant\", \n",
    "        \"Introspective journey\", \"Contemplative\", \"Bittersweet\", \"Quiet strength\", \n",
    "        \"Life lessons\", \"Inner journey\", \"Mood-driven\", \"Calmly intense\"\n",
    "    ],\n",
    "    \"Broken Clouds\": [\n",
    "        \"Broken Clouds\", \"Mysterious\", \"Suspenseful\", \"Reflective\", \"Dark\", \"Intense\",\n",
    "        \"Haunting\", \"Eerie\", \"Moody\", \"Complex\", \"Shadowy\", \"Gripping\",\n",
    "        \"Unsettling\", \"Enigmatic\", \"Foreboding\", \"Unpredictable\", \"Intrigue\", \n",
    "        \"Atmospheric tension\", \"Sinister\", \"Psychological\", \"Mind-bending\", \n",
    "        \"Chilling\", \"Darkly intense\", \"Surreal\", \"Strange happenings\", \"Edge of seat\"\n",
    "    ],\n",
    "    \"Shower Rain\": [\n",
    "        \"Shower Rain\", \"Cozy\", \"Introspective\", \"Emotional\", \"Comforting\", \"Reflective\",\n",
    "        \"Meditative\", \"Contemplative\", \"Heartfelt\", \"Warm\", \"Sentimental\", \"Quiet\",\n",
    "        \"Reassuring\", \"Tranquil\", \"Peaceful\", \"Gentle\", \"Soul-soothing\", \n",
    "        \"Intimate moments\", \"Personal growth\", \"Tender connections\", \"Reflective warmth\", \n",
    "        \"Gentle stories\", \"Warm nostalgia\", \"Softly dramatic\", \"Comforting escape\", \n",
    "        \"Simple yet profound\", \"Delicate storytelling\"\n",
    "    ],\n",
    "    \"Rain\": [\n",
    "        \"Rain\", \"Nostalgic\", \"Melancholic\", \"Reflective\", \"Introspective\", \"Calm\",\n",
    "        \"Serene\", \"Meditative\", \"Peaceful\", \"Thought-provoking\", \"Somber\", \"Moody\",\n",
    "        \"Soft\", \"Quiet\", \"Pensive\", \"Healing\", \"Deep contemplation\", \"Solemn beauty\", \n",
    "        \"Pensive reflection\", \"Sad yet hopeful\", \"Soothing sadness\", \"Inner peace\", \n",
    "        \"Emotional release\", \"Softly moving\", \"Heartache\", \"Life's reflections\", \n",
    "        \"Gentle sadness\", \"Releasing burdens\"\n",
    "    ],\n",
    "    \"Thunderstorm\": [\n",
    "        \"Thunderstorm\", \"Suspenseful\", \"Exciting\", \"Dark\", \"Adventurous\", \"Intense\",\n",
    "        \"Thrilling\", \"Dangerous\", \"Bold\", \"Fierce\", \"Dynamic\", \"Powerful\",\n",
    "        \"Gripping\", \"Dramatic\", \"Raw\", \"Electrifying\", \"High stakes\", \"Adrenaline rush\", \n",
    "        \"Fearless pursuits\", \"Shocking revelations\", \"Unpredictable\", \"Stormy emotions\", \n",
    "        \"Battle scenes\", \"Action-packed\", \"Survival stories\", \"Strong-willed heroes\", \n",
    "        \"Chaotic situations\", \"Riveting suspense\"\n",
    "    ],\n",
    "    \"Snow\": [\n",
    "        \"Snow\", \"Cozy\", \"Nostalgic\", \"Introspective\", \"Comforting\", \"Reflective\",\n",
    "        \"Peaceful\", \"Calm\", \"Serene\", \"Heartwarming\", \"Magical\", \"Pure\",\n",
    "        \"Soft\", \"Innocent\", \"Blissful\", \"Quiet\", \"Wintry magic\", \"Simple joys\", \n",
    "        \"Serenity\", \"Innocence\", \"Warm hugs\", \"Winter’s wonder\", \"Nostalgic memories\", \n",
    "        \"Childlike wonder\", \"Gentle reflections\", \"Family warmth\", \"Magical stories\", \n",
    "        \"Softly lit\", \"Seasonal joy\", \"Finding home\"\n",
    "    ],\n",
    "    \"Mist\": [\n",
    "        \"Mist\", \"Mysterious\", \"Suspenseful\", \"Dark\", \"Eerie\", \"Thought-provoking\",\n",
    "        \"Foggy\", \"Enigmatic\", \"Creepy\", \"Haunting\", \"Vague\", \"Surreal\",\n",
    "        \"Strange\", \"Bewildering\", \"Unsettling\", \"Cryptic\", \"Unsettling calm\", \n",
    "        \"Otherworldly\", \"Dreamlike\", \"Mind-bending\", \"Haunting suspense\", \n",
    "        \"Unanswered questions\", \"Psychological tension\", \"Eerie landscapes\", \n",
    "        \"Unearthly quiet\", \"Spooky tales\", \"Shadowy figures\", \"Intangible fears\", \n",
    "        \"Lost in fog\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb11a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to start (or use an existing one if available)\n",
    "current_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each weather type and its keywords\n",
    "for weather_type, keywords in weather_keywords.items():\n",
    "    print(f\"Processing weather type: {weather_type}\")\n",
    "    \n",
    "    # For each keyword associated with the weather type, call the function\n",
    "    for keyword in keywords:\n",
    "        print(f\"Searching for movies with keyword: '{keyword}' under weather type '{weather_type}'\")\n",
    "        \n",
    "        # Call the function and update the dataset with movies associated with each keyword\n",
    "        current_df = add_movies_by_keyword_to_dataset(keyword, current_df, weather_type)\n",
    "        print(\"\\nCurrent dataset head:\")\n",
    "        print(current_df.head())\n",
    "        \n",
    "        print(\"\\nCurrent dataset info:\")\n",
    "        print(current_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85835a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting dataset\n",
    "print(\"Final dataset:\")\n",
    "print(current_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337ef85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, save the final dataset to a CSV file\n",
    "current_df.to_csv(\"movies_with_weather_associations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd4b78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d44642c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m current_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmovies_with_weather_associations.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8-sig\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2061\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "current_df = pd.read_csv(\"movies_with_weather_associations.csv\", encoding=\"utf-8-sig\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weather_type, keywords in weather_keywords2.items():\n",
    "    print(f\"Processing weather type: {weather_type}\")\n",
    "    \n",
    "    # For each keyword associated with the weather type, call the function\n",
    "    for keyword in keywords:\n",
    "        print(f\"Searching for movies with keyword: '{keyword}' under weather type '{weather_type}'\")\n",
    "        \n",
    "        # Call the function and update the dataset with movies associated with each keyword\n",
    "        current_df2 = add_movies_by_keyword_to_dataset(keyword, current_df2, weather_type)\n",
    "        print(\"\\nCurrent dataset head:\")\n",
    "        print(current_df.head())\n",
    "        \n",
    "        print(\"\\nCurrent dataset info:\")\n",
    "        print(current_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3192ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_df2.to_csv(\"updated_dataset.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
